{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-Whitening细解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Heisenberg\n",
    "\n",
    "@date: 2021-01-16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code was share from Jianlin Su on his blog:\n",
    "\n",
    "https://kexue.fm/archives/8069\n",
    "\n",
    "And This is a repo.\n",
    "\n",
    "Data can be download from:\n",
    "\n",
    "https://gluebenchmark.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试任务：GLUE的STS-B句子相似性任务\n",
    "\n",
    "测试环境：tf2.2.0+ keras2.3.1+ bert4keras 0.9.8\n",
    "\n",
    "对向量进行线性变换（即数据挖掘中的**白化**操作）可达到BERT-Flow的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:41:35.079912Z",
     "start_time": "2021-01-16T02:41:05.601441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.snippets import open, sequence_padding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:41:59.900203Z",
     "start_time": "2021-01-16T02:41:59.896214Z"
    }
   },
   "source": [
    "## 读取并加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:42:16.861186Z",
     "start_time": "2021-01-16T02:42:16.814582Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_train_data(filename):\n",
    "    \"\"\"加载训练数据（带标签）\n",
    "    单条格式：(文本1, 文本2, 标签)\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if i > 0:\n",
    "                l = l.strip().split('\\t')\n",
    "                D.append((l[-2], l[-1], float(l[-3])))\n",
    "    return D\n",
    "\n",
    "\n",
    "def load_test_data(filename):\n",
    "    \"\"\"加载测试数据（带标签）\n",
    "    单条格式：(文本1, 文本2, 标签)\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            l = l.strip().split('\\t')\n",
    "            D.append((l[-2], l[-1], float(l[-3])))\n",
    "    return D\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "train_data = load_train_data('STS-B/original/sts-train.tsv')\n",
    "test_data = load_test_data('STS-B/original/sts-dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:43:18.704468Z",
     "start_time": "2021-01-16T02:43:18.698311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A man is playing a large flute.', 'A man is playing a flute.', 3.8)\n",
      "('A man with a hard hat is dancing.', 'A man wearing a hard hat is dancing.', 5.0)\n"
     ]
    }
   ],
   "source": [
    "#(文本1, 文本2, 相似性分数x(/5.0))\n",
    "print(train_data[0])\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:44:05.695573Z",
     "start_time": "2021-01-16T02:44:05.691923Z"
    }
   },
   "source": [
    "## 加载Bert与分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:44:54.887378Z",
     "start_time": "2021-01-16T02:44:54.843494Z"
    }
   },
   "outputs": [],
   "source": [
    "config_path = 'bert/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'bert/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'bert/uncased_L-12_H-768_A-12/vocab.txt'\n",
    "\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)  # 建立分词器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义全局池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:48:00.485832Z",
     "start_time": "2021-01-16T02:48:00.479849Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1D(keras.layers.GlobalAveragePooling1D):\n",
    "    \"\"\"自定义全局池化\n",
    "    \"\"\"\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())[:, :, None]\n",
    "            return K.sum(inputs * mask, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return K.mean(inputs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:48:21.734292Z",
     "start_time": "2021-01-16T02:48:04.535540Z"
    }
   },
   "outputs": [],
   "source": [
    "bert = build_transformer_model(config_path, checkpoint_path)\n",
    "\n",
    "encoder_layers, count = [], 0\n",
    "while True:\n",
    "    try:\n",
    "        output = bert.get_layer(\n",
    "            'Transformer-%d-FeedForward-Norm' % count\n",
    "        ).output\n",
    "        encoder_layers.append(output)\n",
    "        count += 1\n",
    "    except:\n",
    "        break\n",
    "\n",
    "n_last, outputs = 2, []\n",
    "for i in range(n_last):\n",
    "    outputs.append(GlobalAveragePooling1D()(encoder_layers[-i]))\n",
    "\n",
    "output = keras.layers.Average()(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最后的编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:48:21.763797Z",
     "start_time": "2021-01-16T02:48:21.756815Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Model(bert.inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换文本数据为id形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:48:56.161792Z",
     "start_time": "2021-01-16T02:48:56.153804Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_vecs(data, maxlen=64):\n",
    "    \"\"\"转换文本数据为id形式\n",
    "    \"\"\"\n",
    "    a_token_ids, b_token_ids, labels = [], [], []\n",
    "    for d in data:\n",
    "        token_ids = tokenizer.encode(d[0], maxlen=maxlen)[0]\n",
    "        a_token_ids.append(token_ids)\n",
    "        token_ids = tokenizer.encode(d[1], maxlen=maxlen)[0]\n",
    "        b_token_ids.append(token_ids)\n",
    "        labels.append(d[2])\n",
    "    a_token_ids = sequence_padding(a_token_ids)\n",
    "    b_token_ids = sequence_padding(b_token_ids)\n",
    "    a_vecs = encoder.predict([a_token_ids,\n",
    "                              np.zeros_like(a_token_ids)],\n",
    "                             verbose=True)\n",
    "    b_vecs = encoder.predict([b_token_ids,\n",
    "                              np.zeros_like(b_token_ids)],\n",
    "                             verbose=True)\n",
    "    return a_vecs, b_vecs, np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:49:16.460465Z",
     "start_time": "2021-01-16T02:49:16.456478Z"
    }
   },
   "source": [
    "## 计算kernel和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:49:27.406786Z",
     "start_time": "2021-01-16T02:49:27.400802Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_kernel_bias(vecs):\n",
    "    \"\"\"计算kernel和bias\n",
    "    最后的变换：y = (x + bias).dot(kernel)\n",
    "    \"\"\"\n",
    "    vecs = np.concatenate(vecs, axis=0)\n",
    "    mu = vecs.mean(axis=0, keepdims=True)\n",
    "    cov = np.cov(vecs.T)\n",
    "    u, s, vh = np.linalg.svd(cov)\n",
    "    W_inv = np.dot(u, np.diag(s**0.5))\n",
    "    W = np.linalg.inv(W_inv.T)\n",
    "    return W, -mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变换及标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:50:58.609239Z",
     "start_time": "2021-01-16T02:50:58.603255Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_and_normalize(vecs, kernel=None, bias=None):\n",
    "    \"\"\"应用变换，然后标准化\n",
    "    \"\"\"\n",
    "    if not (kernel is None or bias is None):\n",
    "        vecs = (vecs + bias).dot(kernel)\n",
    "    return vecs / (vecs**2).sum(axis=1, keepdims=True)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料向量化，计算变换矩阵和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:52:35.014513Z",
     "start_time": "2021-01-16T02:51:11.018275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5551/5551 [==============================] - 41s 7ms/step\n",
      "5551/5551 [==============================] - 39s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "a_train_vecs, b_train_vecs, train_labels = convert_to_vecs(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:55:11.971968Z",
     "start_time": "2021-01-16T02:54:54.326790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478/1478 [==============================] - 8s 5ms/step\n",
      "1478/1478 [==============================] - 9s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "a_test_vecs, b_test_vecs, test_labels = convert_to_vecs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:55:33.155903Z",
     "start_time": "2021-01-16T02:55:33.150916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "#将训练集和测试集的句子都转化为768维的向量\n",
    "print(len(a_train_vecs[0]))\n",
    "print(len(a_test_vecs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T02:56:33.484851Z",
     "start_time": "2021-01-16T02:56:33.124084Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel, bias = compute_kernel_bias([a_train_vecs, b_train_vecs, a_test_vecs, b_test_vecs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel bias计算详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:02:38.105263Z",
     "start_time": "2021-01-16T11:02:38.067199Z"
    }
   },
   "outputs": [],
   "source": [
    "all_vecs = np.concatenate([a_train_vecs, b_train_vecs, a_test_vecs, b_test_vecs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T03:00:04.870874Z",
     "start_time": "2021-01-16T03:00:04.865887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14058, 768)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_vecs是（5551+5551+1478+1478）× 768维的矩阵\n",
    "all_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于768列的每个维度的均值向量$\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T03:01:21.690567Z",
     "start_time": "2021-01-16T03:01:21.674908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = all_vecs.mean(axis=0, keepdims=True)\n",
    "mu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "768列之间的相关系数矩阵 $\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T03:03:16.237229Z",
     "start_time": "2021-01-16T03:03:16.088321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = np.cov(all_vecs.T)\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据SVD分解$\\Sigma=U\\Lambda U^{\\top}$及$\\Sigma=(W^{-1})^{\\top}W^{-1}$计算得$W^{-1}=U\\sqrt{\\Lambda}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:48:14.063137Z",
     "start_time": "2021-01-16T10:48:13.877852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n",
      "(768,)\n",
      "(768, 768)\n"
     ]
    }
   ],
   "source": [
    "u, s, vh = np.linalg.svd(cov)\n",
    "print(u.shape)\n",
    "print(s.shape)\n",
    "print(vh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解$ W^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:51:36.736182Z",
     "start_time": "2021-01-16T10:51:36.719228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_inv = np.dot(u, np.diag(s**0.5))\n",
    "W_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解$W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:52:32.267490Z",
     "start_time": "2021-01-16T10:52:32.232259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.linalg.inv(W_inv.T)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:56:27.059551Z",
     "start_time": "2021-01-16T10:56:27.055557Z"
    }
   },
   "source": [
    "### 变换及标准化详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T10:56:04.953605Z",
     "start_time": "2021-01-16T10:56:04.672972Z"
    }
   },
   "outputs": [],
   "source": [
    "a_train_vecs = transform_and_normalize(a_train_vecs, kernel, bias)\n",
    "b_train_vecs = transform_and_normalize(b_train_vecs, kernel, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照$\\tilde{x_i}=(x_i-\\mu)W$进行变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:02:19.126319Z",
     "start_time": "2021-01-16T11:02:18.902661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14058, 768)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs = (all_vecs-mu).dot(W)\n",
    "all_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:18:14.420237Z",
     "start_time": "2021-01-16T11:18:14.415282Z"
    }
   },
   "source": [
    "按照$x_i^{\\prime}=\\frac{x_i}{\\sqrt{\\Sigma x_i^2}}$进行L2正则化的预处理，即$\|x\|_{p}=\left(\left|x_{1}\right|^{p}+\left|x_{2}\right|^{p}+\ldots+\left|x_{a}\right|^{p}\right)^{\frac{1}{p}}$，$\tilde{x_i}=\frac{x_i}{\|x\|_{p}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:14:54.070849Z",
     "start_time": "2021-01-16T11:14:53.956858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14058, 768)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs = all_vecs/(all_vecs**2).sum(axis=1,keepdims=True)**0.5\n",
    "all_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:19:18.399140Z",
     "start_time": "2021-01-16T11:19:18.395176Z"
    }
   },
   "source": [
    "### 计算训练集中句子相关分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:29:12.421649Z",
     "start_time": "2021-01-16T11:29:12.414670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.71206009],\n",
       "       [0.71206009, 1.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(train_labels, train_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:19:42.920148Z",
     "start_time": "2021-01-16T11:19:42.879258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的相关系数：0.7120600911305668\n"
     ]
    }
   ],
   "source": [
    "train_sims = (a_train_vecs * b_train_vecs).sum(axis=1)\n",
    "print(u'训练集的相关系数：%s' % np.corrcoef(train_labels, train_sims)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关于np.corrcorf(X,Y):\n",
    "\n",
    "返回相关系数矩阵\n",
    "\n",
    "$R(x,y)=\\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}}=\\frac{E(XY)-E(X)E(Y)}{\\sqrt{Var(X)Var(Y)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:56:14.725112Z",
     "start_time": "2021-01-16T11:56:14.719128Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819805060619656"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[0,1]意为取第0行第1列的数\n",
    "np.corrcoef([1,3,5],[2,4,5])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$r = \\frac{13-3*\\frac{11}{3}}{1.633*1.247}=0.98198$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算测试集中句子相关分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T11:20:31.306863Z",
     "start_time": "2021-01-16T11:20:31.213178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集的相关系数：0.7745647933327217\n"
     ]
    }
   ],
   "source": [
    "a_test_vecs = transform_and_normalize(a_test_vecs, kernel, bias)\n",
    "b_test_vecs = transform_and_normalize(b_test_vecs, kernel, bias)\n",
    "test_sims = (a_test_vecs * b_test_vecs).sum(axis=1)\n",
    "print(u'测试集的相关系数：%s' % np.corrcoef(test_labels, test_sims)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
